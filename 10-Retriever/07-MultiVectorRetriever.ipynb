{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96a9939",
   "metadata": {},
   "source": [
    "# MultiVectorRetriever\n",
    "\n",
    "- Author: [YooKyung Jeon](https://github.com/sirena1)\n",
    "- Peer Review: [choincnp](https://github.com/choincnp), [Hye-yoonJeong](https://github.com/Hye-yoonJeong)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/99-TEMPLATE/00-BASE-TEMPLATE-EXAMPLE.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In LangChain, there's a special feature called `MultiVectorRetriever` that enables efficient querying of documents in various contexts. This feature allows documents to be stored and managed with multiple vectors, significantly enhancing the accuracy and efficiency of information retrieval.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Methods for Generating Multiple Vectors Per Document](#methods-for-generating-multiple-vectors-per-document)\n",
    "- [Chunk + Original Document Retrieval](#chunk--original-document-retrieval)\n",
    "- [Storing summaries in vector storage](#storing-summaries-in-vector-storage)\n",
    "- [Utilizing Hypothetical Queries to explore document content](#utilizing-hypothetical-queries-to-explore-document-content)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Retriever](https://python.langchain.com/docs/integrations/retrievers)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37cf0d8",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a1f4952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "29876d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain_community\",\n",
    "        \"langchain\",\n",
    "        \"langchain_chroma\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"pymupdf\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e5c356c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"07-MultiVectorRetriever\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "56ec0472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949f426",
   "metadata": {},
   "source": [
    "## Methods for Generating Multiple Vectors Per Document\n",
    "\n",
    "1. **Creating Small Chunks**: Divide the document into smaller chunks and generate separate embeddings for each chunk. This method enables a more granular focus on specific parts of the document. It can be implemented using the `ParentDocumentRetriever`, making it easier to explore detailed information.\n",
    "\n",
    "2. **Summary Embeddings**: Generate a summary for each document and create embeddings based on this summary. Summary embeddings are particularly useful for quickly grasping the core content of a document. By focusing only on the summary instead of analyzing the entire document, efficiency can be significantly improved.\n",
    "\n",
    "3. **Utilizing Hypothetical Questions**: Create relevant hypothetical questions for each document and generate embeddings based on these questions. This approach is helpful when deeper exploration of specific topics or content is needed. Hypothetical questions enable a broader perspective on the document's content, facilitating a more comprehensive understanding.\n",
    "\n",
    "4. **Manual Addition**: Users can manually add specific questions or queries that should be considered during document retrieval. This method provides users with more control over the search process, allowing for customized searches tailored to their specific needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b574ec5",
   "metadata": {},
   "source": [
    "The preprocessing process involves loading data from a text file and splitting the loaded documents into specified sizes.\n",
    "\n",
    "The split documents can later be used for tasks such as vectorization and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0d6c52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader(\"data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453afd1e",
   "metadata": {},
   "source": [
    "The original documents loaded from the data are stored in the `docs` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "12a50910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE - A POLICY PERSPECTIVE\n",
      "6\n",
      "data for innovators, particularly in the business-to-business (B2B) \n",
      "or government-to-citizens (G2C) domains: e.g. by open access to \n",
      "government data in sectors such as transportation and health-\n",
      "care (Burghin et al., 2019), privacy-preserving data marketplaces \n",
      "for companies to share data (de Streel et al., 2019). The genuine \n",
      "concern for innovators access to data is shown by the city of Bar-\n",
      "celona where ‘data sovereignty’\n"
     ]
    }
   ],
   "source": [
    "print(docs[5].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ef408",
   "metadata": {},
   "source": [
    "## Chunk + Original Document Retrieval\n",
    "\n",
    "When searching through large volumes of information, embedding data into smaller chunks can be highly beneficial.\n",
    "\n",
    "With `MultiVectorRetriever`, documents can be stored and managed as multiple vectors.\n",
    "\n",
    "- The original documents are stored in the `docstore`.\n",
    "- The embedded documents are stored in the `vectorstore`.\n",
    "\n",
    "This allows for splitting documents into smaller units, enabling more accurate searches. Additionally, the contents of the original document can be accessed when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "404582fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['46aba7dd-39cd-4852-beed-e8e0560e7a98', 'dc741e0e-89a0-41b5-8090-688ec75748b8']\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "\n",
    "# Vector store for indexing child chunks\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"small_bigger_chunks\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# Storage layer for parent documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Retriever (initially empty)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "\n",
    "# Generate document IDs\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
    "\n",
    "# Verify two of the generated IDs\n",
    "print(doc_ids[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80961f",
   "metadata": {},
   "source": [
    "Here we define a `parent_text_splitter` for splitting into larger chunks and a `child_text_splitter` for splitting into smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3bc95363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RecursiveCharacterTextSplitter object for larger chunks\n",
    "parent_text_splitter = RecursiveCharacterTextSplitter(chunk_size=600)\n",
    "\n",
    "# Splitter to be used for generating smaller chunks\n",
    "child_text_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e48a98",
   "metadata": {},
   "source": [
    "Create Parent documents as larger chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f4437c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_docs = []\n",
    "\n",
    "for i, doc in enumerate(docs):\n",
    "    # Retrieve the ID of the current document\n",
    "    _id = doc_ids[i]\n",
    "    # Split the current document into smaller parent documents\n",
    "    parent_doc = parent_text_splitter.split_documents([doc])\n",
    "\n",
    "    for _doc in parent_doc:\n",
    "        # Store the document ID in the metadata\n",
    "        _doc.metadata[id_key] = _id\n",
    "    parent_docs.extend(parent_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c5b0e5",
   "metadata": {},
   "source": [
    "Verify the `doc_id` assigned to `parent_docs`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f8d7ff8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf',\n",
       " 'file_path': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 24,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Adobe InDesign 15.1 (Macintosh)',\n",
       " 'producer': 'Adobe PDF Library 15.0',\n",
       " 'creationDate': \"D:20200922223534+02'00'\",\n",
       " 'modDate': \"D:20200922223544+02'00'\",\n",
       " 'trapped': '',\n",
       " 'doc_id': '46aba7dd-39cd-4852-beed-e8e0560e7a98'}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metadata of the generated Parent documents.\n",
    "parent_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f680da0",
   "metadata": {},
   "source": [
    "Create Child documents as relatively smaller chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e56afe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_docs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # Retrieve the ID of the current document\n",
    "    _id = doc_ids[i]\n",
    "    # Split the current document into child documents\n",
    "    child_doc = child_text_splitter.split_documents([doc])\n",
    "    for _doc in child_doc:\n",
    "        # Store the document ID in the metadata\n",
    "        _doc.metadata[id_key] = _id\n",
    "    child_docs.extend(child_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe5cb5",
   "metadata": {},
   "source": [
    "Verify the `doc_id` assigned to `child_docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "80857992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf',\n",
       " 'file_path': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf',\n",
       " 'page': 0,\n",
       " 'total_pages': 24,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': '',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'creator': 'Adobe InDesign 15.1 (Macintosh)',\n",
       " 'producer': 'Adobe PDF Library 15.0',\n",
       " 'creationDate': \"D:20200922223534+02'00'\",\n",
       " 'modDate': \"D:20200922223544+02'00'\",\n",
       " 'trapped': '',\n",
       " 'doc_id': '46aba7dd-39cd-4852-beed-e8e0560e7a98'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the metadata of the generated Child documents.\n",
    "child_docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a346a79",
   "metadata": {},
   "source": [
    "Check the number of chunks for each split document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6dfd9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split parent_docs: 177\n",
      "Number of split child_docs: 950\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of split parent_docs: {len(parent_docs)}\")\n",
    "print(f\"Number of split child_docs: {len(child_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da6ab64",
   "metadata": {},
   "source": [
    "Add the newly created smaller child document set to the vector store\n",
    "\n",
    "Next, map the parent documents to the generated UUIDs and add them to the `docstore`.\n",
    "\n",
    "- Use the `mset()` method to store document IDs and their content as key-value pairs in the document store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a291a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add both parent and child documents to the vector store\n",
    "retriever.vectorstore.add_documents(parent_docs)\n",
    "retriever.vectorstore.add_documents(child_docs)\n",
    "\n",
    "# Store the original documents in the docstore\n",
    "retriever.docstore.mset(list(zip(doc_ids, docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a644c1",
   "metadata": {},
   "source": [
    "Perform Similarity Search and Display the Most Similar Document Chunk\n",
    "\n",
    "Use the `retriever.vectorstore.similarity_search` method to search within child and parent document chunks.\n",
    "\n",
    "The first document chunk with the highest similarity will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a0d9ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved documents: 4\n"
     ]
    }
   ],
   "source": [
    "# Perform similarity search on the vectorstore\n",
    "relevant_chunks = retriever.vectorstore.similarity_search(\n",
    "    \"What is the phased implementation timeline for the EU AI Act?\"\n",
    ")\n",
    "print(f\"Number of retrieved documents: {len(relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e5eb7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in relevant_chunks:\n",
    "    print(chunk.page_content, end=\"\\n\\n\")\n",
    "    print(\">\" * 100, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598f6f1a",
   "metadata": {},
   "source": [
    "Execute a Query Using the `retriever.invoke()` Method\n",
    "\n",
    "The `retriever.invoke()` method performs a search across the full content of the original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1a29f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of retrieved documents: 1\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE - A POLICY PERSPECTIVE\n",
      "5\n",
      "laws and regulation. Some negative examples have been given \n",
      "wide attention in the media: a fatal accident involving an autono-\n",
      "mous vehicle2; Microsoft’s chatting bot Tay being shut down after \n",
      "16 hours because it became racist, sexist, and denied the Holo-\n",
      "caust3; racially biased decisions with credit checks and recidivism \n",
      "(Teich & Tirias Research, 2018). Such examples are fuelling a va-\n",
      "riety of concerns about accountability, fairness, bias, autonomy, \n",
      "and due process of AI systems (Pasquale, 2015; Ziewitz, 2015). \n",
      "Beyond these anecdotal instances, AI presents several challenges \n",
      "(Dwivedi et al., 2019), which are economic (need of funds, impact \n",
      "on employment and performances) and organizational (changing \n",
      "working practices, cultural barriers, need of new skills, data inte-\n",
      "gration, etc.) issues to be tackled. At societal level AI may challenge \n",
      "cultural norms and face resistance (Hu et al, 2019). In Europe there \n",
      "is an ongoing discussion on the legal and ethical challenges posed \n",
      "by a greater use of AI. One key point is transparency, or lack the-\n",
      "reof, of algorithms on which AI applications rely. There is a need \n",
      "to study and understand where algorithms may go wrong as to \n",
      "adopt adequate and proportional remedial and mitigation mea-\n",
      "sures. Algorithmic rules may imply moral judgements, such as for \n",
      "driverless cars deciding which lives to save in the event of a se-\n",
      "rious accident (Nyholm, & Smids, 2016). \n",
      "The European Commission has launched a series of policy initia-\n",
      "tives with the aim to boost the development of sustainable AI \n",
      "in Europe, including the communication ‘Artificial Intelligence for \n",
      "Europe’ (European Commission, 2018a), the declaration of coo-\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to \n",
      "place people at the centre of the development of AI, what has been \n",
      "called ‘human-centric AI’. It is a three-pronged approach to support \n",
      "the EU’s technological and industrial capacity and AI uptake across \n",
      "the economy, prepare for socio-economic changes, and ensure an \n",
      "appropriate ethical and legal framework. The Commission has set \n",
      "up a High-Level Expert Group on AI representing a wide range of \n",
      "stakeholders and has tasked it with drafting AI ethics guidelines as \n",
      "well as preparing a set of recommendations for broader AI policy. \n",
      "The Group drafted AI Ethical Guidelines4, which postulate that in \n",
      "order to achieve ‘trustworthy AI’, three components are necessary: \n",
      "(1) it should comply with the law, (2) it should fulfil ethical prin-\n",
      "ciples and (3) it should be robust. Based on these three compo-\n",
      "nents and the European values, the guidelines identify seven key \n",
      "requirements that AI applications should respect to be considered \n",
      "trustworthy5. These policies culminated in the White Paper on AI \n",
      "– A European Approach to Excellence and Trust (European Com-\n",
      "mission, 2020a) and a Communication on ‘A European Strategy \n",
      "for Data’ (European Commission, 2020b). The strategy set out in \n",
      "the Paper is built on two main blocks. On the one hand, it aims to \n",
      "create an ‘ecosystem of excellence’, by boosting the development \n",
      "of AI, partnering with private sector, focusing on R&D, skills and \n",
      "SMEs in particular. On the other hand, it aims to create an ‘ecosys-\n",
      "tem of trust’ within an EU regulatory framework. The strategy set \n",
      "out in the White Paper is to build and retain trust in AI. This needs \n",
      "a multi-layered approach that includes critical engagement of civil \n",
      "society to discuss the values guiding and being embedded into AI; \n",
      "public debates to translate these values into strategies and guide-\n",
      "lines; and responsible design practices that encode these values \n",
      "and guidelines into AI systems making these ‘ethical by design’. \n",
      "In line with this we have the European data strategy, adopted in \n",
      "February 2020, aiming to establish a path for the creation of Euro-\n",
      "pean data spaces whereby more data becomes available for use in \n",
      "the economy and society but under firm control of European com-\n",
      "panies and individuals. As noted in a recent parliamentary brief \n",
      "(European Parliament, 2020), the objective of creating European \n",
      "data spaces is related to the ongoing discourse on Europe digital \n",
      "sovereignty (EPSC, 20196)  and the concern that, while Europe is at \n",
      "the frontier in terms of research and on a par with its global com-\n",
      "petitors, it nonetheless lags behind the US and China when it co-\n",
      "mes to private investment (European Commission, 2018a). The le-\n",
      "vel of adoption of AI technologies by companies and by the general \n",
      "public appears comparatively low compared to the US (Probst et \n",
      "al., 2018). This leads to the concern that citizens, businesses and \n",
      "Member States of the EU are gradually losing control over their \n",
      "data, their capacity for innovation, and their ability to shape and \n",
      "enforce legislation in the digital environment. To address these \n",
      "concerns the data strategy proposes the construction of an EU \n",
      "data framework that would favour and support the sharing of \n",
      "\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.invoke(\n",
    "    \"What is the phased implementation timeline for the EU AI Act?\"\n",
    ")\n",
    "print(f\"Number of retrieved documents: {len(relevant_docs)}\", end=\"\\n\\n\")\n",
    "print(\"=\" * 100, end=\"\\n\\n\")\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc30896",
   "metadata": {},
   "source": [
    "The default search type performed by the retriever in the vector database is similarity search.\n",
    "\n",
    "LangChain Vector Stores also support searching using [Max Marginal Relevance](https://api.python.langchain.com/en/latest/vectorstores/langchain_core.vectorstores.VectorStore.html#langchain_core.vectorstores.VectorStore.max_marginal_relevance_search). \n",
    "\n",
    "If you want to use this method instead, you can configure the `search_type` property as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac718689",
   "metadata": {},
   "source": [
    "- Set the `search_type` property of the `retriever` object to `SearchType.mmr`.\n",
    "  - This specifies that the MMR (Maximal Marginal Relevance) algorithm should be used during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c545fc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE - A POLICY PERSPECTIVE\n",
      "5\n",
      "laws and regulation. Some negative examples have been given \n",
      "wide attention in the media: a fatal accident involving an autono-\n",
      "mous vehicle2; Microsoft’s chatting bot Tay being shut down after \n",
      "16 hours because it became racist, sexist, and denied the Holo-\n",
      "caust3; racially biased decisions with credit checks and recidivism \n",
      "(Teich & Tirias Research, 2018). Such examples are fuelling a va-\n",
      "riety of concerns about accountability, fairness, bias, autonomy, \n",
      "and due process of AI systems (Pasquale, 2015; Ziewitz, 2015). \n",
      "Beyond these anecdotal instances, AI presents several challenges \n",
      "(Dwivedi et al., 2019), which are economic (need of funds, impact \n",
      "on employment and performances) and organizational (changing \n",
      "working practices, cultural barriers, need of new skills, data inte-\n",
      "gration, etc.) issues to be tackled. At societal level AI may challenge \n",
      "cultural norms and face resistance (Hu et al, 2019). In Europe there \n",
      "is an ongoing discussion on the legal and ethical challenges posed \n",
      "by a greater use of AI. One key point is transparency, or lack the-\n",
      "reof, of algorithms on which AI applications rely. There is a need \n",
      "to study and understand where algorithms may go wrong as to \n",
      "adopt adequate and proportional remedial and mitigation mea-\n",
      "sures. Algorithmic rules may imply moral judgements, such as for \n",
      "driverless cars deciding which lives to save in the event of a se-\n",
      "rious accident (Nyholm, & Smids, 2016). \n",
      "The European Commission has launched a series of policy initia-\n",
      "tives with the aim to boost the development of sustainable AI \n",
      "in Europe, including the communication ‘Artificial Intelligence for \n",
      "Europe’ (European Commission, 2018a), the declaration of coo-\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to \n",
      "place people at the centre of the development of AI, what has been \n",
      "called ‘human-centric AI’. It is a three-pronged approach to support \n",
      "the EU’s technological and industrial capacity and AI uptake across \n",
      "the economy, prepare for socio-economic changes, and ensure an \n",
      "appropriate ethical and legal framework. The Commission has set \n",
      "up a High-Level Expert Group on AI representing a wide range of \n",
      "stakeholders and has tasked it with drafting AI ethics guidelines as \n",
      "well as preparing a set of recommendations for broader AI policy. \n",
      "The Group drafted AI Ethical Guidelines4, which postulate that in \n",
      "order to achieve ‘trustworthy AI’, three components are necessary: \n",
      "(1) it should comply with the law, (2) it should fulfil ethical prin-\n",
      "ciples and (3) it should be robust. Based on these three compo-\n",
      "nents and the European values, the guidelines identify seven key \n",
      "requirements that AI applications should respect to be considered \n",
      "trustworthy5. These policies culminated in the White Paper on AI \n",
      "– A European Approach to Excellence and Trust (European Com-\n",
      "mission, 2020a) and a Communication on ‘A European Strategy \n",
      "for Data’ (European Commission, 2020b). The strategy set out in \n",
      "the Paper is built on two main blocks. On the one hand, it aims to \n",
      "create an ‘ecosystem of excellence’, by boosting the development \n",
      "of AI, partnering with private sector, focusing on R&D, skills and \n",
      "SMEs in particular. On the other hand, it aims to create an ‘ecosys-\n",
      "tem of trust’ within an EU regulatory framework. The strategy set \n",
      "out in the White Paper is to build and retain trust in AI. This needs \n",
      "a multi-layered approach that includes critical engagement of civil \n",
      "society to discuss the values guiding and being embedded into AI; \n",
      "public debates to translate these values into strategies and guide-\n",
      "lines; and responsible design practices that encode these values \n",
      "and guidelines into AI systems making these ‘ethical by design’. \n",
      "In line with this we have the European data strategy, adopted in \n",
      "February 2020, aiming to establish a path for the creation of Euro-\n",
      "pean data spaces whereby more data becomes available for use in \n",
      "the economy and society but under firm control of European com-\n",
      "panies and individuals. As noted in a recent parliamentary brief \n",
      "(European Parliament, 2020), the objective of creating European \n",
      "data spaces is related to the ongoing discourse on Europe digital \n",
      "sovereignty (EPSC, 20196)  and the concern that, while Europe is at \n",
      "the frontier in terms of research and on a par with its global com-\n",
      "petitors, it nonetheless lags behind the US and China when it co-\n",
      "mes to private investment (European Commission, 2018a). The le-\n",
      "vel of adoption of AI technologies by companies and by the general \n",
      "public appears comparatively low compared to the US (Probst et \n",
      "al., 2018). This leads to the concern that citizens, businesses and \n",
      "Member States of the EU are gradually losing control over their \n",
      "data, their capacity for innovation, and their ability to shape and \n",
      "enforce legislation in the digital environment. To address these \n",
      "concerns the data strategy proposes the construction of an EU \n",
      "data framework that would favour and support the sharing of \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set the search type to Maximal Marginal Relevance (MMR)\n",
    "retriever.search_type = SearchType.mmr\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    retriever.invoke(\n",
    "        \"What is the phased implementation timeline for the EU AI Act?\"\n",
    "    )[0].page_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "07d08019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE - A POLICY PERSPECTIVE\n",
      "5\n",
      "laws and regulation. Some negative examples have been given \n",
      "wide attention in the media: a fatal accident involving an autono-\n",
      "mous vehicle2; Microsoft’s chatting bot Tay being shut down after \n",
      "16 hours because it became racist, sexist, and denied the Holo-\n",
      "caust3; racially biased decisions with credit checks and recidivism \n",
      "(Teich & Tirias Research, 2018). Such examples are fuelling a va-\n",
      "riety of concerns about accountability, fairness, bias, autonomy, \n",
      "and due process of AI systems (Pasquale, 2015; Ziewitz, 2015). \n",
      "Beyond these anecdotal instances, AI presents several challenges \n",
      "(Dwivedi et al., 2019), which are economic (need of funds, impact \n",
      "on employment and performances) and organizational (changing \n",
      "working practices, cultural barriers, need of new skills, data inte-\n",
      "gration, etc.) issues to be tackled. At societal level AI may challenge \n",
      "cultural norms and face resistance (Hu et al, 2019). In Europe there \n",
      "is an ongoing discussion on the legal and ethical challenges posed \n",
      "by a greater use of AI. One key point is transparency, or lack the-\n",
      "reof, of algorithms on which AI applications rely. There is a need \n",
      "to study and understand where algorithms may go wrong as to \n",
      "adopt adequate and proportional remedial and mitigation mea-\n",
      "sures. Algorithmic rules may imply moral judgements, such as for \n",
      "driverless cars deciding which lives to save in the event of a se-\n",
      "rious accident (Nyholm, & Smids, 2016). \n",
      "The European Commission has launched a series of policy initia-\n",
      "tives with the aim to boost the development of sustainable AI \n",
      "in Europe, including the communication ‘Artificial Intelligence for \n",
      "Europe’ (European Commission, 2018a), the declaration of coo-\n",
      "peration on AI (European Commission, 2018c), and coordinated \n",
      "action plan on the development of AI in the EU (European Com-\n",
      "mission, 2018d), among others. The European strategy aims to \n",
      "place people at the centre of the development of AI, what has been \n",
      "called ‘human-centric AI’. It is a three-pronged approach to support \n",
      "the EU’s technological and industrial capacity and AI uptake across \n",
      "the economy, prepare for socio-economic changes, and ensure an \n",
      "appropriate ethical and legal framework. The Commission has set \n",
      "up a High-Level Expert Group on AI representing a wide range of \n",
      "stakeholders and has tasked it with drafting AI ethics guidelines as \n",
      "well as preparing a set of recommendations for broader AI policy. \n",
      "The Group drafted AI Ethical Guidelines4, which postulate that in \n",
      "order to achieve ‘trustworthy AI’, three components are necessary: \n",
      "(1) it should comply with the law, (2) it should fulfil ethical prin-\n",
      "ciples and (3) it should be robust. Based on these three compo-\n",
      "nents and the European values, the guidelines identify seven key \n",
      "requirements that AI applications should respect to be considered \n",
      "trustworthy5. These policies culminated in the White Paper on AI \n",
      "– A European Approach to Excellence and Trust (European Com-\n",
      "mission, 2020a) and a Communication on ‘A European Strategy \n",
      "for Data’ (European Commission, 2020b). The strategy set out in \n",
      "the Paper is built on two main blocks. On the one hand, it aims to \n",
      "create an ‘ecosystem of excellence’, by boosting the development \n",
      "of AI, partnering with private sector, focusing on R&D, skills and \n",
      "SMEs in particular. On the other hand, it aims to create an ‘ecosys-\n",
      "tem of trust’ within an EU regulatory framework. The strategy set \n",
      "out in the White Paper is to build and retain trust in AI. This needs \n",
      "a multi-layered approach that includes critical engagement of civil \n",
      "society to discuss the values guiding and being embedded into AI; \n",
      "public debates to translate these values into strategies and guide-\n",
      "lines; and responsible design practices that encode these values \n",
      "and guidelines into AI systems making these ‘ethical by design’. \n",
      "In line with this we have the European data strategy, adopted in \n",
      "February 2020, aiming to establish a path for the creation of Euro-\n",
      "pean data spaces whereby more data becomes available for use in \n",
      "the economy and society but under firm control of European com-\n",
      "panies and individuals. As noted in a recent parliamentary brief \n",
      "(European Parliament, 2020), the objective of creating European \n",
      "data spaces is related to the ongoing discourse on Europe digital \n",
      "sovereignty (EPSC, 20196)  and the concern that, while Europe is at \n",
      "the frontier in terms of research and on a par with its global com-\n",
      "petitors, it nonetheless lags behind the US and China when it co-\n",
      "mes to private investment (European Commission, 2018a). The le-\n",
      "vel of adoption of AI technologies by companies and by the general \n",
      "public appears comparatively low compared to the US (Probst et \n",
      "al., 2018). This leads to the concern that citizens, businesses and \n",
      "Member States of the EU are gradually losing control over their \n",
      "data, their capacity for innovation, and their ability to shape and \n",
      "enforce legislation in the digital environment. To address these \n",
      "concerns the data strategy proposes the construction of an EU \n",
      "data framework that would favour and support the sharing of \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set search type to similarity_score_threshold\n",
    "retriever.search_type = SearchType.similarity_score_threshold\n",
    "retriever.search_kwargs = {\"score_threshold\": 0.3}\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    retriever.invoke(\n",
    "        \"What is the phased implementation timeline for the EU AI Act?\"\n",
    "    )[0].page_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d203555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_vector import SearchType\n",
    "\n",
    "# Set search type to similarity and k value to 1\n",
    "retriever.search_type = SearchType.similarity\n",
    "retriever.search_kwargs = {\"k\": 1}\n",
    "\n",
    "# Search all related documents\n",
    "print(\n",
    "    len(\n",
    "        retriever.invoke(\n",
    "            \"What is the phased implementation timeline for the EU AI Act?\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d961b6c",
   "metadata": {},
   "source": [
    "## Storing summaries in vector storage\n",
    "\n",
    "Summaries can often provide a more accurate extraction of the contents of a chunk, which can lead to better search results.\n",
    "\n",
    "This section describes how to generate summaries and how to embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e7c44d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split documents: 135\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries for loading PDF files and splitting text\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Initialize the PDF file loader\n",
    "loader = PyMuPDFLoader(\"data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf\")\n",
    "\n",
    "# Split text\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=50)\n",
    "\n",
    "# Load a PDF file and run Text Split\n",
    "split_docs = loader.load_and_split(text_splitter)\n",
    "\n",
    "# Output the number of split documents\n",
    "print(f\"Number of split documents: {len(split_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a161ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "summary_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # Create a prompt template for document summaries\n",
    "    | ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert in summarizing documents in English.\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Summarize the following documents in 3 sentences in bullet points format.\\n\\n{doc}\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    # Using OpenAI's ChatGPT model to generate summaries\n",
    "    | ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b79165",
   "metadata": {},
   "source": [
    "Summarize the documents in the `docs` list in batch using the `chain.batch` method.\n",
    "- Here, we set the `max_concurrency` parameter to 10 to allow up to 10 documents to be processed simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f7fe3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling batches of documents\n",
    "summaries = summary_chain.batch(split_docs, {\"max_concurrency\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "45363e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a11208",
   "metadata": {},
   "source": [
    "Print the summary to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "436bd00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision-making process may become less tractable9. The chosen \n",
      "decision model may also turn out to be unsuitable if the real-world \n",
      "environment behaves differently from what was expected. While \n",
      "more and better data be used for training can help improving pre-\n",
      "diction, it will never be perfect or include all justifiable outliers. On \n",
      "the other hand, as technology advances more instruments may \n",
      "become available to quantify the degree of influence of input va-\n",
      "riables on algorithm outputs (Datta et al., 2016). Research is also \n",
      "underway in pursuit of rendering algorithms more amenable to\n",
      "\n",
      "[summary]\n",
      "- The decision-making process can become complex and less manageable if the chosen model does not align with real-world conditions.  \n",
      "- Although improved data can enhance predictions, it will never be flawless or account for all valid outliers.  \n",
      "- Advancements in technology may provide new tools to measure the impact of input variables on algorithm outputs, and research is ongoing to make algorithms more adaptable.  \n"
     ]
    }
   ],
   "source": [
    "# Prints the contents of the original document.\n",
    "print(split_docs[33].page_content, end=\"\\n\\n\")\n",
    "# Print a summary.\n",
    "print(\"[summary]\")\n",
    "print(summaries[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da5865",
   "metadata": {},
   "source": [
    "Initialize the `Chroma` vector store to index the child chunks. Use `OpenAIEmbeddings` as the embedding function.\n",
    "\n",
    "- Use `“doc_id”` as the key representing the document ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bbe2f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Create a vector store to store the summary information.\n",
    "summary_vectorstore = Chroma(\n",
    "    collection_name=\"summaries\",\n",
    "    embedding_function=OpenAIEmbeddings(model=\"text-embedding-3-small\"),\n",
    ")\n",
    "\n",
    "# Create a repository to store the parent document.\n",
    "store = InMemoryStore()\n",
    "\n",
    "# Specify a key name to store the document ID.\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Initialize the searcher (empty at startup).\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=summary_vectorstore,  # vector store\n",
    "    byte_store=store,  # byte store\n",
    "    id_key=id_key,  # document ID\n",
    ")\n",
    "# Create a document ID.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d0e2c6",
   "metadata": {},
   "source": [
    "Save the summarized document and its metadata (here, the `Document ID` for the summary you created).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "cec99148",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_docs = [\n",
    "    # Create a Document object with the summary as the page content and the document ID as metadata.\n",
    "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "    for i, s in enumerate(summaries)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb07ac1",
   "metadata": {},
   "source": [
    "The number of articles in the digest matches the number of original articles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d36e4d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents in the summary\n",
    "len(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4400de8c",
   "metadata": {},
   "source": [
    "- Add `summary_docs` to the vector store with `retriever.vectorstore.add_documents(summary_docs)`.\n",
    "- Map `doc_ids` and `docs` with `retriever.docstore.mset(list(zip(doc_ids, docs))))` to store them in the document store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "df7ce3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.vectorstore.add_documents(\n",
    "    summary_docs\n",
    ")  # Add the summarized document to the vector repository.\n",
    "\n",
    "# Map the document ID to the document and store it in the document store.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9158831",
   "metadata": {},
   "source": [
    "Perform a similarity search using the `similarity_search` method of the `vectorstore` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "89e3d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search.\n",
    "result_docs = summary_vectorstore.similarity_search(\n",
    "    \"What is the phased implementation timeline for the EU AI Act?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ae7cb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The European Commission and EU member states are collaborating to enhance the development and implementation of artificial intelligence (AI) technologies within Europe.  \n",
      "- In 2018, a commitment was made to boost AI \"made in Europe,\" focusing on fostering innovation and ensuring ethical standards.  \n",
      "- The 2020 White Paper outlines a European approach to AI, emphasizing the importance of excellence and trust in AI systems.\n"
     ]
    }
   ],
   "source": [
    "# Output 1 result document.\n",
    "print(result_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd64a80",
   "metadata": {},
   "source": [
    "Use the `invoke()` of the `retriever` object to retrieve documents related to your question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c5a9c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cial Intelligence. Retrieved from https://ec.europa.eu/digital-single-market/en/news/\n",
      "eu-member-states-sign-cooperate-artificial-intelligence.\n",
      "European Commission. (2018d). Member States and Commission to work together to \n",
      "boost artificial intelligence ‘made in Europe’. Retrieved from https://ec.europa.eu/commis-\n",
      "sion/presscorner/detail/en/IP_18_6689.\n",
      "European Commission. (2020a). White Paper on Artificial Intelligence. A European Ap-\n",
      "proach to Excellence and Trust. COM(2020) 65 final, Brussels: European Commission.\n"
     ]
    }
   ],
   "source": [
    "# Search for and fetch related articles.\n",
    "retrieved_docs = retriever.invoke(\n",
    "    \"What is the phased implementation timeline for the EU AI Act?\"\n",
    ")\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d5f1b",
   "metadata": {},
   "source": [
    "## Utilizing Hypothetical Queries to explore document content\n",
    "\n",
    "LLM can also be used to generate a list of questions that can be hypothesized about a particular document.\n",
    "\n",
    "These generated questions can be embedded to further explore and understand the content of the document.\n",
    "\n",
    "Generating hypothetical questions can help you identify key topics and concepts in your documentation, and can encourage readers to ask more questions about the content of your documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7933e03",
   "metadata": {},
   "source": [
    "Below is an example of creating a hypothesis question utilizing `Function Calling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5baf8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"hypothetical_questions\",  # Specify a name for the function.\n",
    "        \"description\": \"Generate hypothetical questions\",  # Write a description of the function.\n",
    "        \"parameters\": {  # Define the parameters of the function.\n",
    "            \"type\": \"object\",  # Specifies the type of the parameter as an object.\n",
    "            \"properties\": {  # Defines the properties of an object.\n",
    "                \"questions\": {  # Define the 'questions' attribute.\n",
    "                    \"type\": \"array\",  # Type 'questions' as an array.\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },  # Specifies the array's element type as String.\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"questions\"],  # Specify 'questions' as a required parameter.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa557a",
   "metadata": {},
   "source": [
    "Use `ChatPromptTemplate` to define a prompt template that generates three hypothetical questions based on the given document.\n",
    "\n",
    "- Set `functions` and `function_call` to call the virtual question generation functions.\n",
    "- Use `JsonKeyOutputFunctionsParser` to parse the generated virtual questions and extract the values corresponding to the `questions` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7cb4be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "hypothetical_query_chain = (\n",
    "    {\"doc\": lambda x: x.page_content}\n",
    "    # We ask you to create exactly 3 hypothetical questions that you can answer using the documentation below. This number can be adjusted.\n",
    "    | ChatPromptTemplate.from_template(\n",
    "        \"Generate a list of exactly 3 hypothetical questions that the below document could be used to answer. \"\n",
    "        \"Potential users are those interested in the AI industry. Create questions that they would be interested in. \"\n",
    "        \"Output should be written in English:\\n\\n{doc}\"\n",
    "    )\n",
    "    | ChatOpenAI(max_retries=0, model=\"gpt-4o-mini\").bind(\n",
    "        functions=functions, function_call={\"name\": \"hypothetical_questions\"}\n",
    "    )\n",
    "    # Extract the value corresponding to the “questions” key from the output.\n",
    "    | JsonKeyOutputFunctionsParser(key_name=\"questions\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b789211",
   "metadata": {},
   "source": [
    "Output the answers to the documents.\n",
    "\n",
    "- The output contains the three Hypothetical Queries you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a9cda3be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How might advancements in technology influence the accuracy of decision-making algorithms in the AI industry?',\n",
       " 'What could be the consequences if decision models in AI fail to adapt to unexpected changes in real-world environments?',\n",
       " 'In what ways could the availability of better data impact the training of AI algorithms and their ability to predict outcomes?']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the chain for the given document.\n",
    "hypothetical_query_chain.invoke(split_docs[33])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ff912",
   "metadata": {},
   "source": [
    "Use the `chain.batch` method to process multiple requests for `split_docs` data at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ac642190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch of hypothetical questions for a list of articles\n",
    "hypothetical_questions = hypothetical_query_chain.batch(\n",
    "    split_docs, {\"max_concurrency\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "02840bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What could happen if an AI decision-making model is trained on incomplete or biased data?',\n",
       " 'How might advancements in technology influence the reliability of AI predictions in unpredictable environments?',\n",
       " 'What would be the implications for the AI industry if algorithms could be made more transparent and interpretable in their decision-making processes?']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_questions[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ded0",
   "metadata": {},
   "source": [
    "Below is the process for storing the Hypothetical Queries you created in Vector Storage, the same way we did before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c44404c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector store to use for indexing child chunks\n",
    "hypothetical_vectorstore = Chroma(\n",
    "    collection_name=\"hypo-questions\", embedding_function=OpenAIEmbeddings()\n",
    ")\n",
    "# Storage hierarchy for parent documents\n",
    "store = InMemoryStore()\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "# Retriever (empty on startup)\n",
    "retriever = MultiVectorRetriever(\n",
    "    vectorstore=hypothetical_vectorstore,\n",
    "    byte_store=store,\n",
    "    id_key=id_key,\n",
    ")\n",
    "doc_ids = [str(uuid.uuid4()) for _ in split_docs]  # Create a document ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8a6b7",
   "metadata": {},
   "source": [
    "Add metadata (document IDs) to the `question_docs` list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a7cbb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_docs = []\n",
    "# save hypothetical_questions\n",
    "for i, question_list in enumerate(hypothetical_questions):\n",
    "    question_docs.extend(\n",
    "        # Create a Document object for each question in the list of questions, and include the document ID for that question in the metadata.\n",
    "        [Document(page_content=s, metadata={id_key: doc_ids[i]}) for s in question_list]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a8e5f",
   "metadata": {},
   "source": [
    "Add the hypothesized query to the document, and add the original document to `docstore`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "105ecf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the hypothetical_questions document to the vector repository.\n",
    "retriever.vectorstore.add_documents(question_docs)\n",
    "\n",
    "# Map the document ID to the document and store it in the document store.\n",
    "retriever.docstore.mset(list(zip(doc_ids, split_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb5835",
   "metadata": {},
   "source": [
    "Perform a similarity search using the `similarity_search` method of the `vectorstore` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ca9afb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the vector repository for similar documents.\n",
    "result_docs = hypothetical_vectorstore.similarity_search(\n",
    "    \"What is the phased implementation timeline for the EU AI Act?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce41e6",
   "metadata": {},
   "source": [
    "Below are the results of the similarity search.\n",
    "\n",
    "Here, we've only added the hypothesized query we created, so it returns the documents with the highest similarity among the hypothesized queries we created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "10c33bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What potential socio-economic changes could arise from the implementation of the EU's coordinated action plan on AI?\n",
      "{'doc_id': 'accd841f-1474-410f-b600-54e646eac1ec'}\n",
      "How might the guidelines set by the Next European Commission impact the regulatory landscape for AI in Europe?\n",
      "{'doc_id': '73899cc8-b216-4642-906c-1e73b49bd479'}\n",
      "What might be the long-term effects of implementing the operational principles outlined in the EC AI White Paper on the AI industry in Europe?\n",
      "{'doc_id': 'dcf69a31-e872-4bef-b4f0-190bb3a8889c'}\n",
      "What potential scenarios could arise from the implementation of the proposed AI governance regimes in Europe, and how might they affect the AI industry?\n",
      "{'doc_id': 'ba58ee93-5bad-4ba9-958b-4e0af5fc0162'}\n"
     ]
    }
   ],
   "source": [
    "# Output the results of the similarity search.\n",
    "for doc in result_docs:\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88722c7",
   "metadata": {},
   "source": [
    "Use the `invoke` method of the `retriever` object to retrieve documents related to the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d106a8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guidelines for the Next European Commission 2019-2024. Retrieved from: https://ec.eu-\n",
      "ropa.eu/commission/sites/beta-political/files/political-guidelines-next-commission_en-\n",
      ".pdf.\n",
      "Wachter, S., Mittelstadt, B., & Floridi, L. (2017). Transparent, explainable, and accountable \n",
      "AI for robotics. Science Robotics, 2(6), eaan6080. doi:10.1126/scirobotics.aan6080.\n",
      "Wachter, S., Mittelstadt, B., & Russell, C. (2018). Counterfactual Explanations Without Ope-\n",
      "ning the Black Box: Automated Decisions and the GDPR. Harvard Journal of Law & Tech-\n",
      "nology, 31(2), 841-887.\n",
      "reof, of algorithms on which AI applications rely. There is a need \n",
      "to study and understand where algorithms may go wrong as to \n",
      "adopt adequate and proportional remedial and mitigation mea-\n",
      "sures. Algorithmic rules may imply moral judgements, such as for \n",
      "driverless cars deciding which lives to save in the event of a se-\n",
      "rious accident (Nyholm, & Smids, 2016). \n",
      "The European Commission has launched a series of policy initia-\n",
      "tives with the aim to boost the development of sustainable AI \n",
      "in Europe, including the communication ‘Artificial Intelligence for\n",
      "ferences to production and delivery (i.e., the Industry 4.0 vision). \n",
      "Manufacturing companies are investing into this vision and are \n",
      "keen to protect their intellectual property generated from such in-\n",
      "vestments. So, there is a concern that a potential new legislative \n",
      "action by the European Commission, which would follow the prin-\n",
      "ciples of the GDPR and the requirements of the White Paper, may\n",
      "(21/11/2019).\n",
      "Goodman, B., & Flaxman, S. (2017). European Union regulations on algorithmic deci-\n",
      "sion-making and a ‘right to explanation. AI Magazine, 38(3), 50-57., 38(3), 50-57. \n",
      "Hof, R. (2013, April 23). Deep Learning. The MIT Technology Review. Retrieved from https://\n",
      "www.technologyreview.com/s/513696/deep-learning/.\n",
      "Jia, R., & Liang, P. (2016). Data Recombination for Neural Semantic Parsing. Paper pre-\n",
      "sented at the Annual Meeting of the Association for Computational Linguistics, Berlin.\n",
      "Klossa, G. (2019). Towards European Media Sovereignity. An Industrial Media Strategy\n"
     ]
    }
   ],
   "source": [
    "# Search for and fetch related articles.\n",
    "retrieved_docs = retriever.invoke(result_docs[1].page_content)\n",
    "\n",
    "# Output the documents found.\n",
    "for doc in retrieved_docs:\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-HnsOYzrZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
