{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure\n",
    "\n",
    "- Author: [HeeWung Song(Dan)](https://github.com/kofsitho87)\n",
    "- Design: \n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/06-MarkdownHeaderTextSplitter.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/06-MarkdownHeaderTextSplitter.ipynb)\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial, we will explore how to dynamically configure various options when calling a Chain.\n",
    "\n",
    "There are two ways to implement dynamic configuration:\n",
    "\n",
    "- First, the `configurable_fields` method. This method allows you to configure specific fields of a runnable object.\n",
    "- Second, the `configurable_alternatives` method. This method lets you specify alternatives for a particular runnable object that can be set during runtime.\n",
    "\n",
    "`Configurable Fields`\n",
    "- Configurable fields refer to fields that define the system's configuration values.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Configurable Fields](#configurable-fields)\n",
    "- [With HubRunnables](#with-hubrunnables)\n",
    "- [Configurable Alternatives](#configurable-alternatives)\n",
    "- [Setting Prompt Alternatives](#setting-prompt-alternatives)\n",
    "- [Configuring Both Prompts & LLMs](#configuring-both-prompts-&-llms)\n",
    "- [Saving Configurations](#saving-configurations)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain How to configure runtime chain internals](https://python.langchain.com/docs/how_to/configure/)\n",
    "- [LangChain Expression Language (LCEL)](https://python.langchain.com/docs/concepts/lcel/)\n",
    "- [LangChain Chaining runnables](https://python.langchain.com/docs/how_to/sequence/)\n",
    "- [LangChain HubRunnable](https://python.langchain.com/api_reference/langchain/runnables/langchain.runnables.hub.HubRunnable.html)\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Setting up your environment is the first step. See the [Environment Setup](https://wikidocs.net/257836) guide for more details.\n",
    "\n",
    "**[Note]**\n",
    "- The `langchain-opentutorial` is a package of easy-to-use environment setup guidance, useful functions and utilities for tutorials.\n",
    "- Check out the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_openai\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Configure\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can set and load `OPENAI_API_KEY` from a `.env` file.\n",
    "\n",
    "**[Note]** This is only necessary if you haven't already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurable Fields\n",
    "\n",
    "`Configurable fields` provide a way to dynamically modify specific parameters of a runnable object at runtime. This feature is essential when you need to adjust the behavior of your chains or models without changing their core implementation.\n",
    "\n",
    "- They allow you to specify which parameters can be modified during execution\n",
    "- Each field can include a description that explains its purpose\n",
    "- You can configure multiple fields simultaneously\n",
    "- The configuration can be changed for different runs while maintaining the original chain structure\n",
    "\n",
    "The `configurable_fields` method is used to define which parameters should be configurable, making your LangChain applications more flexible and adaptable to different use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Property Configuration\n",
    "\n",
    "When using ChatOpenAI, we can adjust various settings such as `model_name`.\n",
    "\n",
    "The `model_name` property is used to specify the version of GPT. For example, you can select different models by setting it to 'gpt-4o', 'gpt-4o-mini', etc.\n",
    "\n",
    "If you want to dynamically specify the model instead of using a fixed `model_name`, you can convert it to a dynamically configurable property value using `ConfigurableField` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The capital of the United States is Washington, D.C.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 13,\n",
       "   'prompt_tokens': 16,\n",
       "   'total_tokens': 29,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_d28bcae782',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-15070403-58a9-4724-aeed-3a10812fa498-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 16,\n",
       "  'output_tokens': 13,\n",
       "  'total_tokens': 29,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "model.invoke(\"Where is the capital of the United States?\").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).configurable_fields(\n",
    "    # model_name is an original field of ChatOpenAI\n",
    "    model_name=ConfigurableField(\n",
    "        # Set the unique identifier of the field\n",
    "        id=\"gpt_version\",  \n",
    "        # Set the name for model_name\n",
    "        name=\"Version of GPT\",  \n",
    "        # Set the description for model_name\n",
    "        description=\"Official model name of GPTs. ex) gpt-4o, gpt-4o-mini\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When calling `model.invoke()`, you can dynamically specify parameters using the format `config={\"configurable\": {\"key\": \"value\"}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The capital of the United States is Washington, D.C.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 13,\n",
       "   'prompt_tokens': 16,\n",
       "   'total_tokens': 29,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-9f96f444-6e15-412d-8622-840a181452e5-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 16,\n",
       "  'output_tokens': 13,\n",
       "  'total_tokens': 29,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    \"Where is the capital of the United States?\",\n",
    "    # Set gpt_version to gpt-3.5-turbo\n",
    "    config={\"configurable\": {\"gpt_vision\": \"gpt-3.5-turbo\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using the `gpt-4o-mini` model. Check the output to see the changed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The capital of the United States is Washington, D.C.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 13,\n",
       "   'prompt_tokens': 16,\n",
       "   'total_tokens': 29,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0aa8d3e20b',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-d9f59e18-51ee-465f-bb52-118b25fef8a8-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 16,\n",
       "  'output_tokens': 13,\n",
       "  'total_tokens': 29,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\n",
    "    # Set gpt_version to gpt-4o-mini\n",
    "    \"Where is the capital of the United States?\",\n",
    "    config={\"configurable\": {\"gpt_version\": \"gpt-4o-mini\"}},\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set `configurable` parameters using the `with_config()` method of the `model` object. The behavior is the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The capital of the United States is Washington, D.C.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 12,\n",
       "   'prompt_tokens': 16,\n",
       "   'total_tokens': 28,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_d02d531b47',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-f1b5e176-8247-45bb-9ecd-5c93e3e1fc94-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 16,\n",
       "  'output_tokens': 12,\n",
       "  'total_tokens': 28,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.with_config(configurable={\"gpt_version\": \"gpt-4o-mini\"}).invoke(\n",
    "    \"Where is the capital of the United States?\",\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use this function as part of a chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt template from the template\n",
    "prompt = PromptTemplate.from_template(\"Select a random number greater than {x}\")\n",
    "chain = (\n",
    "    prompt | model\n",
    ")  # Create a chain by connecting prompt and model. The prompt's output is passed as input to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': '73',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 2,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 17,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-3.5-turbo-0125',\n",
       "  'system_fingerprint': None,\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-a8764bb6-93f2-4a35-bff3-d635aa1a4b9a-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 2,\n",
       "  'total_tokens': 17,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain and pass 0 as the input variable \"x\"\n",
    "chain.invoke({\"x\": 0}).__dict__  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Sure! Here's a random number greater than 0: 7.\",\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 15,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 30,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_5f20662549',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-3d5c27bd-c9d6-42cd-8a91-467adce4103e-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 15,\n",
       "  'total_tokens': 30,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain with configuration settings\n",
    "chain.with_config(configurable={\"gpt_version\": \"gpt-4o\"}).invoke({\"x\": 0}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With HubRunnables\n",
    "\n",
    "Using `HubRunnable` makes it easy to switch between prompts registered in the Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring LangChain Hub Settings\n",
    "\n",
    "Using `HubRunnable` allows you to configure which prompt template to pull from the LangChain Hub. You can dynamically switch between different prompts by specifying the hub path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableConfigurableFields(default=HubRunnable(bound=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]), kwargs={}, config={}, config_factories=[], owner_repo_commit='rlm/rag-prompt'), fields={'owner_repo_commit': ConfigurableField(id='hub_commit', name='Hub Commit', description='The Hub commit to pull from', annotation=None, is_shared=False)})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.runnables.hub import HubRunnable\n",
    "\n",
    "prompt = HubRunnable(\"rlm/rag-prompt\").configurable_fields(\n",
    "    # ConfigurableField for setting owner repository commit\n",
    "    owner_repo_commit=ConfigurableField(\n",
    "        # Field ID\n",
    "        id=\"hub_commit\",\n",
    "        # Field name\n",
    "        name=\"Hub Commit\",\n",
    "        # Field description\n",
    "        description=\"The Hub commit to pull from\",\n",
    "    )\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you call the `prompt.invoke()` method without specifying a `with_config`, it will pull and use the prompt registered in the initially set `\"rlm/rag-prompt\"` hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: Hello \\nContext: World \\nAnswer:\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the prompt object's invoke method with \"question\" and \"context\" parameters\n",
    "prompt.invoke({\"question\": \"Hello\", \"context\": \"World\"}).messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Please summarize the sentence according to the following REQUEST.\\nREQUEST:\\n1. Summarize the main points in bullet points.\\n2. Each summarized sentence must start with an emoji that fits the meaning of the each sentence.\\n3. Use various emojis to make the summary more interesting.\\n4. DO NOT include any unnecessary information.\\n\\nCONTEXT:\\nHello\\n\\nSUMMARY:\"\\n')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.with_config(\n",
    "    # Set hub_commit to teddynote/summary-stuff-documents\n",
    "    configurable={\"hub_commit\": \"teddynote/summary-stuff-documents\"}\n",
    ").invoke({\"context\": \"Hello\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurable Alternatives\n",
    "\n",
    "**Configurable alternatives** for a Runnable that can be set at runtime.\n",
    "\n",
    "The configurable language model of `ChatAnthropic` provides flexibility that can be applied to various tasks and contexts.\n",
    "\n",
    "To dynamically change configuration values, we set the model parameters as `ConfigurableField` objects.\n",
    "\n",
    "- `model`: Specifies the base language model to use.\n",
    "\n",
    "- `temperature`: A value between 0 and 1 that controls the randomness of sampling. Lower values produce more deterministic and repetitive outputs, while higher values produce more diverse and creative outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Alternatives for LLM Objects\n",
    "\n",
    "Let's explore how to implement this using LLM(Large Language Model).\n",
    "\n",
    "[Note]\n",
    "\n",
    "- To use the `ChatAnthropic` model, you need to obtain and set up an API KEY.\n",
    "- Link: https://console.anthropic.com/dashboard\n",
    "- You can either uncomment and set the API KEY below, or set it in your `.env` file.\n",
    "\n",
    "Set the `ANTHROPIC_API_KEY` environment variable like below.\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"Enter your ANTHROPIC API KEY here.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatAnthropic(\n",
    "    temperature=0, model=\"claude-3-5-sonnet-20241022\"\n",
    ").configurable_alternatives(\n",
    "    # Assign an ID to this field.\n",
    "    # This ID will be used to configure the field when constructing the final runnable object.\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # Set the default key.\n",
    "    # When this key is specified, it will use the default LLM (ChatAnthropic) initialized above.\n",
    "    default_key=\"anthropic\",\n",
    "    # Add a new option named 'openai', which is equivalent to `ChatOpenAI(model=\"gpt-4o-mini\")`.\n",
    "    openai=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    # Add a new option named 'gpt4o', which is equivalent to `ChatOpenAI(model=\"gpt-4o\")`.\n",
    "    gpt4o=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    # You can add more configuration options here.\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"Please briefly explain about {topic}.\")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke a chain using the default LLM `ChatAnthropic` for the method `chain.invoke()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'NewJeans is a South Korean girl group formed by ADOR (All Doors One Room), a subsidiary of HYBE Corporation. The group debuted on July 1, 2022, and consists of five members: Minji, Hanni, Danielle, Haerin, and Hyein. They quickly rose to prominence with their debut single \"Attention\" and follow-up hits like \"Hype Boy\" and \"Ditto.\"\\n\\nThe group is known for their fresh, teen-crush concept and retro-influenced music style that combines various genres including R&B, pop, and hip-hop. Their name \"NewJeans\" is a play on words, referring both to new genes (representing a new generation) and blue jeans (a timeless fashion item).\\n\\nNewJeans has achieved significant commercial success and critical acclaim since their debut, breaking several records and winning multiple awards. They\\'re particularly noted for their strong international appeal and distinctive marketing approach. The group has become one of the most successful fourth-generation K-pop girl groups, known for their sophisticated style and high-quality music productions.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_01LKcn9YZo8eeXHx38ucdKfW',\n",
       "  'model': 'claude-3-5-sonnet-20241022',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'cache_creation_input_tokens': 0,\n",
       "   'cache_read_input_tokens': 0,\n",
       "   'input_tokens': 15,\n",
       "   'output_tokens': 242}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-1f9b71ce-a931-487f-9a26-5e9a6a3c2d22-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 242,\n",
       "  'total_tokens': 257,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke using Anthropic as the default.\n",
    "chain.invoke({\"topic\": \"NewJeans\"}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify a different model to use as the `llm` by using `chain.with_config(configurable={\"llm\": \"model\"})`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'NewJeans is a South Korean girl group formed by ADOR, a subsidiary of HYBE Corporation, which is known for managing successful acts like BTS and TXT. Debuting in August 2022, NewJeans quickly gained popularity for their fresh sound, catchy songs, and unique fashion sense. The group is characterized by their retro-inspired aesthetics and a blend of pop, R&B, and hip-hop influences in their music.\\n\\nThe members of NewJeans include Minji, Hanni, Danielle, Haerin, and Hyein. Their debut EP, titled \"New Jeans,\" featured hit tracks like \"Attention\" and \"Hype Boy,\" which showcased their vocal talents and captivating choreography. The group has been recognized for their innovative approach to music and marketing, including engaging with fans through social media and unique promotional strategies. NewJeans has established itself as a prominent name in the K-pop industry, garnering a dedicated fanbase both in South Korea and internationally.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 196,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 211,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0aa8d3e20b',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-2df17b41-3e7b-47d9-a168-6d7df4e03bdb-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 196,\n",
       "  'total_tokens': 211,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke by changing the chain's configuration.\n",
    "chain.with_config(configurable={\"llm\": \"openai\"}).invoke({\"topic\": \"NewJeans\"}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the chain's configuration to use `gpt4o` as the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"NewJeans is a South Korean girl group formed by ADOR, a subsidiary under HYBE Corporation. The group debuted in July 2022 and quickly gained attention for their fresh concept and music style that sets them apart from traditional K-pop trends. Known for their retro-inspired sound and fashion, NewJeans aims to evoke a sense of nostalgia while appealing to a broad audience through their innovative approach to music and performance. Their debut was marked by the release of singles that showcase their distinctive blend of catchy melodies and youthful energy. The group has been praised for their artistic direction and the members' talents, contributing to their rapid rise in popularity within the K-pop industry.\",\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 134,\n",
       "   'prompt_tokens': 15,\n",
       "   'total_tokens': 149,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_5f20662549',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-60cbd11d-4053-4904-a2aa-c3a5d871cb55-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 134,\n",
       "  'total_tokens': 149,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke by changing the chain's configuration.\n",
    "chain.with_config(configurable={\"llm\": \"gpt4o\"}).invoke({\"topic\": \"NewJeans\"}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the chain's configuration to use `anthropic` as the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'NewJeans is a South Korean girl group formed by ADOR (All Doors One Room), a subsidiary of HYBE Corporation. The group debuted on July 1, 2022, and consists of five members: Minji, Hanni, Danielle, Haerin, and Hyein. They quickly rose to prominence with their debut single \"Attention\" and follow-up hits like \"Hype Boy\" and \"Ditto.\"\\n\\nThe group is known for their fresh, teen-crush concept and retro-influenced music style that combines various genres including R&B, pop, and hip-hop. Their name \"NewJeans\" is a play on words, referring both to new genes (representing a new generation) and blue jeans (a timeless fashion item).\\n\\nNewJeans has achieved significant commercial success and critical acclaim since their debut, breaking several records and winning multiple awards. They\\'re particularly noted for their strong international appeal and distinctive marketing approach, which helped them become one of the most successful fourth-generation K-pop groups.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_01GZLTuXnbTyyFAnE9uh9diZ',\n",
       "  'model': 'claude-3-5-sonnet-20241022',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'cache_creation_input_tokens': 0,\n",
       "   'cache_read_input_tokens': 0,\n",
       "   'input_tokens': 15,\n",
       "   'output_tokens': 229}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-c8e3a472-cbbf-41fe-878c-efe564a029af-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 15,\n",
       "  'output_tokens': 229,\n",
       "  'total_tokens': 244,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke by changing the chain's configuration.\n",
    "chain.with_config(configurable={\"llm\": \"anthropic\"}).invoke(\n",
    "    {\"topic\": \"NewJeans\"}\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Prompt Alternatives\n",
    "\n",
    "Prompts can be configured in a similar way to how we set LLM alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model and set the temperature to 0.\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    # Default prompt template\n",
    "    \"Where is the capital of {country}?\"\n",
    ").configurable_alternatives(\n",
    "    # Assign an ID to this field.\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    # Set the default key.\n",
    "    default_key=\"capital\",\n",
    "    # Add a new option named 'area'.\n",
    "    area=PromptTemplate.from_template(\"What is the area of {country}?\"),\n",
    "    # Add a new option named 'population'.\n",
    "    population=PromptTemplate.from_template(\"What is the population of {country}?\"),\n",
    "    # Add a new option named 'eng'.\n",
    "    kor=PromptTemplate.from_template(\"Translate {input} to Korean.\"),\n",
    "    # You can add more configuration options here.\n",
    ")\n",
    "\n",
    "# Create a chain by connecting the prompt and language model.\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are no configuration changes, the default prompt will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 15, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a2a888c2-cd2f-4159-aa97-0e6dee3b90ac-0', usage_metadata={'input_tokens': 15, 'output_tokens': 9, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain without any configuration changes.\n",
    "chain.invoke({\"country\": \"South Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call a different prompt using `with_config`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The total area of South Korea is approximately 100,363 square kilometers.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 15, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f6ad85fd-369b-47e9-a524-3cb15a113ff7-0', usage_metadata={'input_tokens': 15, 'output_tokens': 16, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain by changing the chain's configuration using with_config.\n",
    "chain.with_config(configurable={\"prompt\": \"area\"}).invoke({\"country\": \"South Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As of 2021, the population of South Korea is approximately 51.8 million.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 15, 'total_tokens': 35, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ddb641f0-154f-470b-a803-ec409aa417f9-0', usage_metadata={'input_tokens': 15, 'output_tokens': 20, 'total_tokens': 35, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain by changing the chain's configuration using with_config.\n",
    "chain.with_config(configurable={\"prompt\": \"population\"}).invoke({\"country\": \"South Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `eng` prompt to request a translation. In this case, the input variable to pass is `input`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='사과는 맛있어요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 15, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-cce73072-7587-4d9d-8a73-4171346899fe-0', usage_metadata={'input_tokens': 15, 'output_tokens': 11, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain by changing the chain's configuration using with_config.\n",
    "chain.with_config(configurable={\"prompt\": \"kor\"}).invoke({\"input\": \"apple is delicious!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Both Prompts & LLMs\n",
    "\n",
    "You can configure multiple aspects using prompts and LLMs together. \n",
    "\n",
    "Here's an example that demonstrates how to use both prompts and LLMs to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(\n",
    "    temperature=0, model=\"claude-3-5-sonnet-20241022\"\n",
    ").configurable_alternatives(\n",
    "    # Assign an ID to this field.\n",
    "    # When configuring the end runnable, we can then use this id to configure this field.\n",
    "    ConfigurableField(id=\"llm\"),\n",
    "    # Set the default key.\n",
    "    # When this key is specified, it will use the default LLM (ChatAnthropic) initialized above.\n",
    "    default_key=\"anthropic\",\n",
    "    # Add a new option named 'openai', which is equivalent to `ChatOpenAI(model=\"gpt-4o-mini\")`.\n",
    "    openai=ChatOpenAI(model=\"gpt-4o-mini\"),\n",
    "    # Add a new option named 'gpt4o', which is equivalent to `ChatOpenAI(model=\"gpt-4o\")`.\n",
    "    gpt4o=ChatOpenAI(model=\"gpt-4o\"),\n",
    "    # You can add more configuration options here.\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    # Default prompt template\n",
    "    \"Describe {company} in 20 words or less.\"\n",
    ").configurable_alternatives(\n",
    "    # Assign an ID to this field.\n",
    "    # When configuring the end runnable, we can then use this id to configure this field.\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    # Set the default key.\n",
    "    default_key=\"description\",\n",
    "    # Add a new option named 'founder'.\n",
    "    founder=PromptTemplate.from_template(\"Who is the founder of {company}?\"),\n",
    "    # Add a new option named 'competitor'.\n",
    "    competitor=PromptTemplate.from_template(\"Who is the competitor of {company}?\"),\n",
    "    # You can add more configuration options here.\n",
    ")\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne on April 1, 1976.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 26,\n",
       "   'prompt_tokens': 14,\n",
       "   'total_tokens': 40,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0aa8d3e20b',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-36c146f6-d689-489f-afae-5c313b504e43-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 14,\n",
       "  'output_tokens': 26,\n",
       "  'total_tokens': 40,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can configure both the prompt and LLM simultaneously using .with_config(). Here we're using the founder prompt template with the OpenAI model.\n",
    "chain.with_config(configurable={\"prompt\": \"founder\", \"llm\": \"openai\"}).invoke(\n",
    "    # Request processing for the company provided by the user.\n",
    "    {\"company\": \"Apple\"}\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Apple is a global technology company known for iPhones, Macs, and innovative consumer electronics, founded by Steve Jobs.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_01N4k3CcSbukLKN22H3FnGST',\n",
       "  'model': 'claude-3-5-sonnet-20241022',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'cache_creation_input_tokens': 0,\n",
       "   'cache_read_input_tokens': 0,\n",
       "   'input_tokens': 18,\n",
       "   'output_tokens': 29}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-3a625785-71dd-4724-91f4-41a0ab157037-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 18,\n",
       "  'output_tokens': 29,\n",
       "  'total_tokens': 47,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to configure the chain to use the Anthropic model, you can do so as follows:\n",
    "chain.with_config(configurable={\"llm\": \"anthropic\"}).invoke(\n",
    "    {\"company\": \"Apple\"}\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Apple has several major competitors across different product categories:\\n\\n1. Smartphones:\\n- Samsung\\n- Google\\n- Huawei\\n- Xiaomi\\n- OnePlus\\n\\n2. Computers/Laptops:\\n- Microsoft\\n- Dell\\n- HP\\n- Lenovo\\n- ASUS\\n\\n3. Tablets:\\n- Samsung\\n- Microsoft (Surface)\\n- Amazon (Fire tablets)\\n- Lenovo\\n\\n4. Smart Watches:\\n- Samsung\\n- Fitbit\\n- Garmin\\n- Huawei\\n\\n5. Music/Media Services:\\n- Spotify\\n- Amazon Music\\n- YouTube Music\\n- Netflix\\n- Disney+\\n\\n6. Software/Operating Systems:\\n- Microsoft\\n- Google (Android/Chrome OS)\\n\\nSamsung is often considered Apple's biggest overall competitor, as it competes in many of the same product categories, particularly in the smartphone market. Microsoft and Google are also major competitors, especially in terms of operating systems and software services.\",\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_017cQyFYwcV46bgo3ekijs7d',\n",
       "  'model': 'claude-3-5-sonnet-20241022',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'cache_creation_input_tokens': 0,\n",
       "   'cache_read_input_tokens': 0,\n",
       "   'input_tokens': 14,\n",
       "   'output_tokens': 217}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-4385dff8-d1e7-4ba3-9ead-84bd335cdd69-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 14,\n",
       "  'output_tokens': 217,\n",
       "  'total_tokens': 231,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to configure the chain to use the competitor prompt template, you can do so as follows:\n",
    "chain.with_config(configurable={\"prompt\": \"competitor\"}).invoke(\n",
    "    {\"company\": \"Apple\"}\n",
    ").__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Apple is a global technology company known for iPhones, Macs, and innovative consumer electronics, founded by Steve Jobs.',\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_01V26p9PhkrZ85NATotyouiC',\n",
       "  'model': 'claude-3-5-sonnet-20241022',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'cache_creation_input_tokens': 0,\n",
       "   'cache_read_input_tokens': 0,\n",
       "   'input_tokens': 18,\n",
       "   'output_tokens': 29}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-b34f7b20-1fff-4f49-8264-13382f91bfe1-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 18,\n",
       "  'output_tokens': 29,\n",
       "  'total_tokens': 47,\n",
       "  'input_token_details': {'cache_read': 0, 'cache_creation': 0}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to use the default configuration, you can invoke the chain directly:\n",
    "chain.invoke({\"company\": \"Apple\"}).__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Configurations\n",
    "\n",
    "You can easily save configured chains as separate objects. For example, after configuring a chain for a specific task, you can save it as a reusable object for similar tasks in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the configured chain to a new variable.\n",
    "gpt4o_competitor_chain = chain.with_config(\n",
    "    configurable={\"llm\": \"gpt4o\", \"prompt\": \"competitor\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'Apple has several competitors across its different product lines. Some of the main competitors include:\\n\\n1. **Smartphones**: \\n   - Samsung\\n   - Google (Pixel)\\n   - Huawei\\n   - Xiaomi\\n\\n2. **Computers and Laptops**:\\n   - Microsoft\\n   - Dell\\n   - HP\\n   - Lenovo\\n\\n3. **Tablets**:\\n   - Samsung\\n   - Microsoft (Surface)\\n   - Amazon (Fire tablets)\\n\\n4. **Wearable Technology**:\\n   - Samsung\\n   - Fitbit\\n   - Garmin\\n\\n5. **Smart Speakers**:\\n   - Amazon (Echo)\\n   - Google (Nest)\\n\\n6. **Streaming Services**:\\n   - Spotify (for Apple Music)\\n   - Netflix, Disney+, Amazon Prime Video (for Apple TV+)\\n\\n7. **Cloud Services**:\\n   - Google\\n   - Microsoft (OneDrive)\\n   - Amazon (AWS)\\n\\nThese competitors challenge Apple in different markets with their own range of products and services.',\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 203,\n",
       "   'prompt_tokens': 14,\n",
       "   'total_tokens': 217,\n",
       "   'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "    'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-2024-08-06',\n",
       "  'system_fingerprint': 'fp_f785eb5f47',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-76f4f809-530d-4a54-a522-8777955a0763-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 14,\n",
       "  'output_tokens': 203,\n",
       "  'total_tokens': 217,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the chain.\n",
    "gpt4o_competitor_chain.invoke({\"company\": \"Apple\"}).__dict__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
