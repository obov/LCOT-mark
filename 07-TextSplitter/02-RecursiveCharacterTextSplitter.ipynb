{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "635d8ebb",
      "metadata": {},
      "source": [
        "# 02. RecursiveCharacterTextSplitter\n",
        "\n",
        "- Author: [fastjw](https://github.com/fastjw)\n",
        "- Design: [fastjw](https://github.com/fastjw)\n",
        "- Peer Review : [Wonyoung Lee](https://github.com/BaBetterB), [sohyunwriter](https://github.com/sohyunwriter)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/02-RecursiveCharacterTextSplitter.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/02-RecursiveCharacterTextSplitter.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial will show you how to use the `RecursiveCharacterTextSplitter`. \n",
        "\n",
        "This is the recommended way to split text.\n",
        "\n",
        "It works by taking a list of characters as a parameter.\n",
        "\n",
        "It tries to split the text into smaller pieces in the order of the given character list until the pieces are very small.\n",
        "\n",
        "By default, the character lists are **['\\n\\n', '\\n', ' \", \"']**.\n",
        "\n",
        "It recursively splits in the following order: **paragraph** -> **sentence** -> **word**.\n",
        "\n",
        "This means that paragraphs (then sentences, then words) are considered to be the most semantically related pieces of text, so we want to keep them together as much as possible.\n",
        "\n",
        "1. How the text is split: by a list of characters (**[‘\\n\\n’, ‘\\n’, ‘ “, ”’]**).\n",
        "2. The chunk size is measured by the number of characters.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [RecursiveCharacterTextSplitter Example](#recursivecharactertextsplitter-example)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain: Recursively split by character](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c7aba4",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21943adb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f25ec196",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain_text_splitters\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f9065ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"RecursiveCharacterTextSplitter\", \n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4f99b5b6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa00c3f4",
      "metadata": {},
      "source": [
        "## RecursiveCharacterTextSplitter Example\n",
        "\n",
        "Read a file for the `RecursiveCharacterTextSplitter` exercise.\n",
        "\n",
        "- Open the **appendix-keywords.txt** file and read its contents.\n",
        "- Save the text to the **file** variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "69cb77da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open the appendix-keywords.txt file to create a file object named f.\n",
        "with open(\"./data/appendix-keywords.txt\") as f:\n",
        "    file = f.read()  # Reads the contents of the file and stores them in the file variable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ccb6bf9",
      "metadata": {},
      "source": [
        "Output some of the contents of the file read from the file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "31638667",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semantic Search\n",
            "\n",
            "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
            "Example: Vectors of word embeddings can be stored in a database for quick access.\n",
            "Related keywords: embedding, database, vectorization, vectorization\n",
            "\n",
            "Embedding\n",
            "\n",
            "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to unders\n"
          ]
        }
      ],
      "source": [
        "# Output the top 500 characters read from the file.\n",
        "print(file[:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b2fc536",
      "metadata": {},
      "source": [
        "Example of using `RecursiveCharacterTextSplitter` to split text into small chunks.\n",
        "\n",
        "- Set **chunk_size** to 250 to limit the size of each chunk.\n",
        "- Set **chunk_overlap** to 50 to allow 50 characters of overlap between neighbouring chunks.\n",
        "- Use the **len** function as **length_function** to calculate the length of the text.\n",
        "- Set **is_separator_regex** to **False** to disable the use of regular expressions as separators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1b78d33f",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set the chunk size to very small. These settings are for illustrative purposes only.\n",
        "    chunk_size=250,\n",
        "    # Sets the number of overlapping characters between chunks.\n",
        "    chunk_overlap=50,\n",
        "    # Specifies a function to calculate the length of the string.\n",
        "    length_function=len,\n",
        "    # Sets whether to use regular expressions as delimiters.\n",
        "    is_separator_regex=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e4d831",
      "metadata": {},
      "source": [
        "- Use **text_splitter** to split the **file** text into documents.\n",
        "- The split documents are stored in the **texts** list.\n",
        "- Print the first and second documents of the split document via **print(texts[0])** and **print(texts[1])**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0874c14b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='Semantic Search'\n",
            "============================================================\n",
            "page_content='Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
            "Example: Vectors of word embeddings can be stored in a database for quick access.'\n"
          ]
        }
      ],
      "source": [
        "# Split the file text into documents using text_splitter.\n",
        "texts = text_splitter.create_documents([file])\n",
        "print(texts[0])  # Outputs the first document in the split document.\n",
        "print(\"===\" * 20)\n",
        "print(texts[1])  # Output the second document of the split document."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c026d703",
      "metadata": {},
      "source": [
        "Use the `text_splitter.split_text()` function to split the **file** text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a2d22b26",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Semantic Search',\n",
              " 'Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\\nExample: Vectors of word embeddings can be stored in a database for quick access.']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Splits the text and returns the first two elements of the split text.\n",
        "text_splitter.split_text(file)[:2]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "3.11.9",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}