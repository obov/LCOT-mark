{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RecursiveJsonSplitter\n",
        "\n",
        "- Author: [HeeWung Song(Dan)](https://github.com/kofsitho87)\n",
        "- Design: \n",
        "- Peer Review :, [BokyungisaGod](https://github.com/BokyungisaGod), [Chaeyoon Kim](https://github.com/chaeyoonyunakim)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/08-RecursiveJsonSplitter.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/07-TextSplitter/08-RecursiveJsonSplitter.ipynb)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This JSON splitter generates smaller JSON chunks by performing a depth-first traversal of JSON data.\n",
        "\n",
        "The splitter aims to keep nested JSON objects intact as much as possible. However, to ensure chunk sizes remain within the `min_chunk_size` and `max_chunk_size`, it will split objects if needed. Note that very large string values (those not containing nested JSON) are not subject to splitting.\n",
        "\n",
        "If precise control over chunk size is required, you can use a **recursive text splitter** on the chunks this splitter creates.\n",
        "\n",
        "**Splitting Criteria**\n",
        "\n",
        "1. Text splitting method: Based on JSON values\n",
        "2. Chunk size: Determined by character count\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Basic JSON Splitting](#basic-json-splitting)\n",
        "- [Handling JSON Structure](#handling-json-structure)\n",
        "\n",
        "\n",
        "### References\n",
        "\n",
        "- [Langchain RecursiveJsonSplitter](https://python.langchain.com/api_reference/text_splitters/json/langchain_text_splitters.json.RecursiveJsonSplitter.html#langchain_text_splitters.json.RecursiveJsonSplitter)\n",
        "- [Langchain How-to-split-JSONdata](https://python.langchain.com/docs/how_to/recursive_json_splitter/)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Setting up your environment is the first step. See the [Environment Setup](https://wikidocs.net/257836) guide for more details.\n",
        "\n",
        "**[Note]**\n",
        "- The `langchain-opentutorial` is a package of easy-to-use environment setup guidance, useful functions and utilities for tutorials.\n",
        "- Check out the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_text_splitters\",\n",
        "        \"langchain_openai\",\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"RecursiveJsonSplitter\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, you can set and load `OPENAI_API_KEY` from a `.env` file.\n",
        "\n",
        "**[Note]** This is only necessary if you haven't already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic JSON Splitting\n",
        "\n",
        "Let's explore the basic methods of splitting JSON data using the `RecursiveJsonSplitter`.\n",
        "\n",
        "- JSON data preparation\n",
        "- `RecursiveJsonSplitter` configuration\n",
        "- Three splitting methods (`split_json`, `create_documents`, and `split_text`)\n",
        "- Chunk size verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# Load the JSON data.\n",
        "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an example of splitting JSON data with the `RecursiveJsonSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveJsonSplitter\n",
        "\n",
        "# Create a RecursiveJsonSplitter object that splits JSON data into chunks with a maximum size of 300\n",
        "splitter = RecursiveJsonSplitter(max_chunk_size=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the `splitter.split_json()` method to recursively split JSON data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recursively split JSON data. Use this when you need to access or manipulate small JSON fragments.\n",
        "json_chunks = splitter.split_json(json_data=json_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code demonstrates two methods for splitting JSON data using a splitter object (like an instance of `RecursiveJsonSplitter`): use the `splitter.create_documents()` method to convert JSON data into `Document` objects, and use the `splitter.split_text()` method to split JSON data into a list of strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}\n",
            "============================================================\n",
            "{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Read Tracer Session\", \"description\": \"Get a specific session.\"}}}}\n"
          ]
        }
      ],
      "source": [
        "# Create documents based on JSON data.\n",
        "docs = splitter.create_documents(texts=[json_data])\n",
        "\n",
        "# Create string chunks based on JSON data.\n",
        "texts = splitter.split_text(json_data=json_data)\n",
        "\n",
        "# Print the first string.\n",
        "print(docs[0].page_content)\n",
        "\n",
        "print(\"===\" * 20)\n",
        "\n",
        "# Print the split string chunks.\n",
        "print(texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handling JSON Structure\n",
        "\n",
        "Let's explore how the `RecursiveJsonSplitter` handles different JSON structures and its limitations.\n",
        "\n",
        "- Verification of list object size\n",
        "- Parsing JSON structures\n",
        "- Using the `convert_lists` parameter for list transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By examining `texts[2]` (one of the larger chunks), we can confirm it contains a list object.\n",
        "\n",
        "- The second chunk exceeds the size limit (300) because it contains a list.\n",
        "- The `RecursiveJsonSplitter` is designed not to split list objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[232, 197, 469, 210, 213, 237, 271, 191, 232, 215]\n",
            "{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}\n"
          ]
        }
      ],
      "source": [
        "# Let's check the size of the chunks\n",
        "print([len(text) for text in texts][:10])\n",
        "\n",
        "# When examining one of the larger chunks, we can see that it contains a list object\n",
        "print(texts[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can parse the chunk at index 2 using the `json` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id',\n",
              "     'in': 'path',\n",
              "     'required': True,\n",
              "     'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}},\n",
              "    {'name': 'include_stats',\n",
              "     'in': 'query',\n",
              "     'required': False,\n",
              "     'schema': {'type': 'boolean',\n",
              "      'default': False,\n",
              "      'title': 'Include Stats'}},\n",
              "    {'name': 'accept',\n",
              "     'in': 'header',\n",
              "     'required': False,\n",
              "     'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}],\n",
              "      'title': 'Accept'}}]}}}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "json_data = json.loads(texts[2])\n",
        "json_data[\"paths\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setting the `convert_lists` parameter to `True` transforms JSON lists into `key:value` pairs (formatted as `index:item`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The following preprocesses JSON and converts lists into dictionaries with index:item as key:value pairs\n",
        "texts = splitter.split_text(json_data=json_data, convert_lists=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": {\"2\": {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": {\"0\": {\"type\": \"string\"}, \"1\": {\"type\": \"null\"}}, \"title\": \"Accept\"}}}}}}}\n"
          ]
        }
      ],
      "source": [
        "# The list has been converted to a dictionary, and we'll check the result.\n",
        "print(texts[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can access specific documents within the `docs` list using their index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"get\": {\"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}, {\"name\": \"include_stats\", \"in\": \"query\", \"required\": false, \"schema\": {\"type\": \"boolean\", \"default\": false, \"title\": \"Include Stats\"}}, {\"name\": \"accept\", \"in\": \"header\", \"required\": false, \"schema\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"title\": \"Accept\"}}]}}}}'\n"
          ]
        }
      ],
      "source": [
        "# Check the document at index 2.\n",
        "print(docs[2])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}